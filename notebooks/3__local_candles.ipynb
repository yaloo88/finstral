{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current notebook's directory\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "# Get the project root (two levels up from the notebook)\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "# Add the project root to Python path\n",
    "sys.path.append(project_root)\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questrade Market Data Management System Notebook\n",
    "\n",
    "This notebook demonstrates how to use the market data management system for Questrade API. The system fetches, stores, and analyzes candlestick data from Questrade's API using SQLite or PostgreSQL databases, with support for Parquet file conversion.\n",
    "\n",
    "## 1. Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import time\n",
    "\n",
    "# Configure the data management system\n",
    "import src.local_symbols as local_symbols\n",
    "import src.qt_api.qt_api as qt\n",
    "import src.local_candles as local_candles\n",
    "\n",
    "# Set up configuration variables\n",
    "# Change these variables in src/local_candles.py \n",
    "DB_SYSTEM = 'sqlite'  # Could be 'postgres' for production \n",
    "DEBUG = True\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Initialization\n",
    "\n",
    "Let's first initialize our database and make sure the required tables exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, ensure our data directory exists\n",
    "local_candles.ensure_data_directory()\n",
    "\n",
    "# Initialize the database\n",
    "local_candles.initialize_db()\n",
    "\n",
    "# Apply database optimizations (indexes)\n",
    "local_candles.optimize_database()\n",
    "\n",
    "# Print database location\n",
    "data_dir = Path('../data')\n",
    "db_path = data_dir / 'candles.db'\n",
    "print(f\"Database initialized at: {db_path}\")\n",
    "\n",
    "# Check database tables\n",
    "with local_candles.get_db_connection() as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    print(\"\\nDatabase tables:\")\n",
    "    for table in tables:\n",
    "        print(f\"- {table[0]}\")\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieving and Storing Candle Data\n",
    "\n",
    "Now, let's explore how to fetch and store candle data for specific symbols.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a symbol we want to work with\n",
    "test_symbol = \"AAPL\"  # Apple Inc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's see how to fetch candle data directly from Questrade API\n",
    "print(f\"Fetching candle data for {test_symbol} from Questrade API...\")\n",
    "candle_df = local_candles.get_candle_df(test_symbol, days_back=7, interval=\"OneMinute\")\n",
    "print(f\"Retrieved {len(candle_df)} candles\")\n",
    "\n",
    "# Display a sample of the data\n",
    "display(candle_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's update the database with this data\n",
    "print(f\"\\nUpdating database with candle data for {test_symbol}...\")\n",
    "local_candles.update_candles_for_symbol(test_symbol, interval=\"OneMinute\")\n",
    "print(\"Update complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data from the database to verify it was stored\n",
    "candles_from_db = local_candles.get_candle_from_db(test_symbol, interval=\"OneMinute\")\n",
    "print(f\"Retrieved {len(candles_from_db)} candles from database\")\n",
    "\n",
    "# Display a sample of the data from the database\n",
    "display(candles_from_db.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with Time Series Data\n",
    "\n",
    "Let's explore how to work with the time series data we've collected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for a specific time period\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=5)).strftime(\"%Y-%m-%d\")\n",
    "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "period_candles = local_candles.get_candles_for_period(\n",
    "    test_symbol, \n",
    "    start_date, \n",
    "    end_date, \n",
    "    interval=\"OneMinute\"\n",
    ")\n",
    "\n",
    "print(f\"Retrieved {len(period_candles)} candles for period {start_date} to {end_date}\")\n",
    "\n",
    "# Convert the 'start' column to datetime for proper plotting\n",
    "period_candles['start'] = pd.to_datetime(period_candles['start'])\n",
    "\n",
    "# Create a simple plot of closing prices\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(period_candles['start'], period_candles['close'])\n",
    "plt.title(f\"{test_symbol} Closing Prices\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get the latest price\n",
    "latest_price = local_candles.get_latest_price(test_symbol)\n",
    "print(f\"Latest price for {test_symbol}: ${latest_price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with Multiple Symbols\n",
    "\n",
    "Let's update multiple symbols and analyze a small portfolio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of symbols for our example portfolio\n",
    "portfolio_symbols = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\"]\n",
    "\n",
    "# Let's manually update our symbols one by one\n",
    "for symbol in portfolio_symbols:\n",
    "    try:\n",
    "        local_candles.update_candles_for_symbol(symbol, interval=\"OneMinute\")\n",
    "        print(f\"Updated {symbol} successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating {symbol}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we could use update_all_symbols() to update all symbols in the database\n",
    "UPDATE_ALL_SYMBOLS = True # Change to True to update all symbols\n",
    "if UPDATE_ALL_SYMBOLS:\n",
    "    print(\"Updating all symbols in database...\")\n",
    "    local_candles.update_all_symbols(backup_db=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Now let's fetch the latest prices for our portfolio\n",
    "portfolio_prices = {}\n",
    "for symbol in portfolio_symbols:\n",
    "    price = local_candles.get_latest_price(symbol)\n",
    "    portfolio_prices[symbol] = price\n",
    "\n",
    "# Create a DataFrame to display the portfolio\n",
    "portfolio_df = pd.DataFrame({\n",
    "    'Symbol': portfolio_prices.keys(),\n",
    "    'Latest Price': portfolio_prices.values()\n",
    "})\n",
    "\n",
    "# Display the portfolio\n",
    "display(portfolio_df)\n",
    "\n",
    "# Create a bar chart of the portfolio prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(portfolio_df['Symbol'], portfolio_df['Latest Price'], color='skyblue')\n",
    "plt.title('Portfolio Latest Prices')\n",
    "plt.xlabel('Symbol')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Converting Database to Parquet Format\n",
    "\n",
    "Parquet is a columnar storage format that provides efficient data compression and encoding schemes, making it good for time series data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_parquet = True # Change to True to run the conversion\n",
    "if run_parquet:\n",
    "    # Convert the database to Parquet format\n",
    "    print(\"Converting database to Parquet format...\")\n",
    "    local_candles.db_to_parquet()\n",
    "\n",
    "# Try to load the Parquet file\n",
    "try:\n",
    "    # Specify the file_name parameter required by load_parquet function\n",
    "    file_name = \"all_candles\"  # Use the base name without timestamp or extension\n",
    "    parquet_df = local_candles.load_parquet(file_name)\n",
    "    print(f\"Loaded Parquet file with {len(parquet_df)} records\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    display(parquet_df.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading parquet file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing Candle Data\n",
    "\n",
    "Let's use our custom function to plot OHLC data for a specific symbol.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use our plotting function to visualize a stock\n",
    "try:\n",
    "    symbol_to_plot = \"AAPL\"\n",
    "    \n",
    "    # Check if the symbol exists in the parquet data\n",
    "    if symbol_to_plot in parquet_df.index.get_level_values('item_id'):  # symbol is in the item_id index\n",
    "        print(f\"Plotting {symbol_to_plot} from Parquet data...\")\n",
    "        local_candles.parquet_plot_ohlc(parquet_df, symbol_to_plot, interval='OneMinute', n_days=120)\n",
    "    else:\n",
    "        print(f\"Symbol '{symbol_to_plot}' not found in Parquet data, trying database...\")\n",
    "        \n",
    "        # Option 2: Plot from database\n",
    "        candles = local_candles.get_candle_from_db(symbol_to_plot, interval=\"OneMinute\")\n",
    "        \n",
    "        if not candles.empty:\n",
    "            # Convert to the format expected by the plotting function\n",
    "            # Use utc=True to avoid FutureWarning about mixed time zones\n",
    "            candles['start'] = pd.to_datetime(candles['start'], utc=True)\n",
    "            # Set the multi-index with item_id (symbol) and timestamp (start)\n",
    "            candles.rename(columns={'symbol': 'item_id'}, inplace=True)\n",
    "            candles.set_index(['item_id', 'start'], inplace=True)\n",
    "            candles.index.names = ['item_id', 'timestamp']\n",
    "            \n",
    "            # Plot the data\n",
    "            local_candles.parquet_plot_ohlc(candles, symbol_to_plot, interval='OneMinute', n_days=1)\n",
    "        else:\n",
    "            print(f\"No data found for symbol '{symbol_to_plot}' with interval 'OneMinute'\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error plotting data: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preparing Data for AutoGluon (Time Series Forecasting)\n",
    "\n",
    "The system includes functionality to prepare data for time series forecasting with AutoGluon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would update all symbols and prepare a combined file for AutoGluon\n",
    "# Note: This can take a long time if you have many symbols\n",
    "print(\"To prepare data for AutoGluon, you would run:\")\n",
    "print(\"ag_data = local_candles.prepare_parquet_autogluon(update_db=True)\")\n",
    "print(\"\\nThis function:\")\n",
    "print(\"1. Updates candle data for all symbols\")\n",
    "print(\"2. Formats the data for time series forecasting\")\n",
    "print(\"3. Saves as a Parquet file with timestamp\")\n",
    "print(\"4. Creates a backup of the database\")\n",
    "\n",
    "# Instead of running the full process, let's demonstrate with a small subset\n",
    "print(\"\\nDemonstrating with a small subset (no updates)...\")\n",
    "\n",
    "# You could run this once a day to update the candle database and get a fresh parquet file\n",
    "PREPARE_AUTOGLUON = True # Change to True to run the conversion\n",
    "if PREPARE_AUTOGLUON:\n",
    "    local_candles.prepare_parquet_autogluon(update_db=False) # Set update_db to True if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Database Maintenance and Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a backup of the database\n",
    "print(\"Creating database backup...\")\n",
    "local_candles.backup_database()\n",
    "\n",
    "# Verify the backup directory\n",
    "backup_dir = Path('../data/backups')\n",
    "if backup_dir.exists():\n",
    "    backups = list(backup_dir.glob(\"*.db\"))\n",
    "    print(f\"Found {len(backups)} database backups:\")\n",
    "    for backup in backups:\n",
    "        backup_size = backup.stat().st_size / (1024 * 1024)  # Convert to MB\n",
    "        print(f\"- {backup.name} ({backup_size:.2f} MB)\")\n",
    "else:\n",
    "    print(\"No backup directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. System Performance Analysis\n",
    "\n",
    "Let's analyze how the system is performing in terms of data storage efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check database size\n",
    "db_size_bytes = db_path.stat().st_size\n",
    "db_size_mb = db_size_bytes / (1024 * 1024)\n",
    "print(f\"Database size: {db_size_mb:.2f} MB\")\n",
    "\n",
    "# Count the number of candles in the database\n",
    "with local_candles.get_db_connection() as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM candles\")\n",
    "    candle_count = cursor.fetchone()[0]\n",
    "    \n",
    "    cursor.execute(\"SELECT COUNT(DISTINCT symbol) FROM candles\")\n",
    "    symbol_count = cursor.fetchone()[0]\n",
    "    \n",
    "    cursor.execute(\"SELECT symbol, COUNT(*) as candle_count FROM candles GROUP BY symbol ORDER BY candle_count DESC LIMIT 10\")\n",
    "    top_symbols = cursor.fetchall()\n",
    "\n",
    "print(f\"Total candles in database: {candle_count:,}\")\n",
    "print(f\"Number of unique symbols: {symbol_count}\")\n",
    "print(f\"Average candles per symbol: {candle_count/symbol_count if symbol_count else 0:,.0f}\")\n",
    "\n",
    "# Print top symbols by candle count\n",
    "print(\"\\nTop symbols by candle count:\")\n",
    "for symbol, count in top_symbols:\n",
    "    print(f\"- {symbol}: {count:,} candles\")\n",
    "\n",
    "# Calculate efficiency metrics\n",
    "bytes_per_candle = db_size_bytes / candle_count if candle_count else 0\n",
    "print(f\"\\nStorage efficiency: {bytes_per_candle:.2f} bytes per candle\")\n",
    "\n",
    "# Check database growth potential\n",
    "estimated_daily_candles_per_symbol = 390  # ~6.5 hours × 60 minutes for US market\n",
    "estimated_daily_growth = estimated_daily_candles_per_symbol * symbol_count * bytes_per_candle / (1024 * 1024)\n",
    "print(f\"Estimated daily database growth: {estimated_daily_growth:.2f} MB\")\n",
    "print(f\"Estimated annual database growth: {estimated_daily_growth * 252:.2f} MB (252 trading days)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "This notebook has demonstrated the key functionality of the Questrade market data management system. The system provides:\n",
    "\n",
    "1. Database initialization and optimization\n",
    "2. Efficient storage of candle data from Questrade API\n",
    "3. Flexible query capabilities for time series analysis\n",
    "4. Support for both SQL and Parquet storage formats\n",
    "5. Visualization tools for market data\n",
    "6. Data preparation for advanced time series forecasting\n",
    "\n",
    "The SQL-based approach offers several advantages:\n",
    "- Efficient storage with indexes for fast queries\n",
    "- Support for complex time-based filtering\n",
    "- Easy backup and maintenance\n",
    "- Integration with both SQLite (for development) and PostgreSQL (for production)\n",
    "\n",
    "With this system, you can build a robust financial data pipeline for algorithmic trading, portfolio analysis, or market research applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
