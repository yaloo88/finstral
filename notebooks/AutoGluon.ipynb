{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "sys.path.append(r'C:\\Users\\Administrator\\finstral-1')\n",
    "import qt_api.qt_api as qt\n",
    "import src.local_symbols as local_symbols\n",
    "import src.local_candles as local_candles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('C:/Users/Administrator/finstral-1/data/parquet/20250406_AG_combined.parquet')]\n",
      "\u001b[94mðŸ“‚ Loading most recent parquet file: 20250406_AG_combined.parquet\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>interval</th>\n",
       "      <th>end</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>industrySector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BRK.B</th>\n",
       "      <th>2025-01-06 06:15:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-01-06 06:16:00</td>\n",
       "      <td>456.10</td>\n",
       "      <td>456.20</td>\n",
       "      <td>456.10</td>\n",
       "      <td>456.20</td>\n",
       "      <td>258</td>\n",
       "      <td>455.882852</td>\n",
       "      <td>FinancialServices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 06:21:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-01-06 06:22:00</td>\n",
       "      <td>456.35</td>\n",
       "      <td>456.35</td>\n",
       "      <td>456.35</td>\n",
       "      <td>456.35</td>\n",
       "      <td>100</td>\n",
       "      <td>455.961142</td>\n",
       "      <td>FinancialServices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 07:00:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-01-06 07:01:00</td>\n",
       "      <td>456.54</td>\n",
       "      <td>456.54</td>\n",
       "      <td>456.07</td>\n",
       "      <td>456.07</td>\n",
       "      <td>300</td>\n",
       "      <td>456.179291</td>\n",
       "      <td>FinancialServices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 07:59:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-01-06 08:00:00</td>\n",
       "      <td>456.30</td>\n",
       "      <td>456.30</td>\n",
       "      <td>456.30</td>\n",
       "      <td>456.30</td>\n",
       "      <td>346</td>\n",
       "      <td>456.208096</td>\n",
       "      <td>FinancialServices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 08:00:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-01-06 08:01:00</td>\n",
       "      <td>456.71</td>\n",
       "      <td>456.71</td>\n",
       "      <td>456.31</td>\n",
       "      <td>456.31</td>\n",
       "      <td>1484</td>\n",
       "      <td>456.240498</td>\n",
       "      <td>FinancialServices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MDB</th>\n",
       "      <th>2025-04-04 18:54:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-04-04 18:55:00</td>\n",
       "      <td>153.95</td>\n",
       "      <td>153.95</td>\n",
       "      <td>153.95</td>\n",
       "      <td>153.95</td>\n",
       "      <td>496</td>\n",
       "      <td>156.060306</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-04 19:00:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-04-04 19:01:00</td>\n",
       "      <td>153.51</td>\n",
       "      <td>153.51</td>\n",
       "      <td>153.51</td>\n",
       "      <td>153.51</td>\n",
       "      <td>110</td>\n",
       "      <td>156.060191</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-04 19:36:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-04-04 19:37:00</td>\n",
       "      <td>153.51</td>\n",
       "      <td>153.51</td>\n",
       "      <td>153.51</td>\n",
       "      <td>153.51</td>\n",
       "      <td>398</td>\n",
       "      <td>156.060250</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-04 19:50:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-04-04 19:51:00</td>\n",
       "      <td>153.50</td>\n",
       "      <td>153.50</td>\n",
       "      <td>153.50</td>\n",
       "      <td>153.50</td>\n",
       "      <td>110</td>\n",
       "      <td>156.060318</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-04 19:59:00</th>\n",
       "      <td>OneMinute</td>\n",
       "      <td>2025-04-04 20:00:00</td>\n",
       "      <td>153.50</td>\n",
       "      <td>153.50</td>\n",
       "      <td>153.50</td>\n",
       "      <td>153.50</td>\n",
       "      <td>693</td>\n",
       "      <td>156.059773</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15765758 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              interval                  end    open    high  \\\n",
       "item_id timestamp                                                             \n",
       "BRK.B   2025-01-06 06:15:00  OneMinute  2025-01-06 06:16:00  456.10  456.20   \n",
       "        2025-01-06 06:21:00  OneMinute  2025-01-06 06:22:00  456.35  456.35   \n",
       "        2025-01-06 07:00:00  OneMinute  2025-01-06 07:01:00  456.54  456.54   \n",
       "        2025-01-06 07:59:00  OneMinute  2025-01-06 08:00:00  456.30  456.30   \n",
       "        2025-01-06 08:00:00  OneMinute  2025-01-06 08:01:00  456.71  456.71   \n",
       "...                                ...                  ...     ...     ...   \n",
       "MDB     2025-04-04 18:54:00  OneMinute  2025-04-04 18:55:00  153.95  153.95   \n",
       "        2025-04-04 19:00:00  OneMinute  2025-04-04 19:01:00  153.51  153.51   \n",
       "        2025-04-04 19:36:00  OneMinute  2025-04-04 19:37:00  153.51  153.51   \n",
       "        2025-04-04 19:50:00  OneMinute  2025-04-04 19:51:00  153.50  153.50   \n",
       "        2025-04-04 19:59:00  OneMinute  2025-04-04 20:00:00  153.50  153.50   \n",
       "\n",
       "                                low   close  volume        VWAP  \\\n",
       "item_id timestamp                                                 \n",
       "BRK.B   2025-01-06 06:15:00  456.10  456.20     258  455.882852   \n",
       "        2025-01-06 06:21:00  456.35  456.35     100  455.961142   \n",
       "        2025-01-06 07:00:00  456.07  456.07     300  456.179291   \n",
       "        2025-01-06 07:59:00  456.30  456.30     346  456.208096   \n",
       "        2025-01-06 08:00:00  456.31  456.31    1484  456.240498   \n",
       "...                             ...     ...     ...         ...   \n",
       "MDB     2025-04-04 18:54:00  153.95  153.95     496  156.060306   \n",
       "        2025-04-04 19:00:00  153.51  153.51     110  156.060191   \n",
       "        2025-04-04 19:36:00  153.51  153.51     398  156.060250   \n",
       "        2025-04-04 19:50:00  153.50  153.50     110  156.060318   \n",
       "        2025-04-04 19:59:00  153.50  153.50     693  156.059773   \n",
       "\n",
       "                                industrySector  \n",
       "item_id timestamp                               \n",
       "BRK.B   2025-01-06 06:15:00  FinancialServices  \n",
       "        2025-01-06 06:21:00  FinancialServices  \n",
       "        2025-01-06 07:00:00  FinancialServices  \n",
       "        2025-01-06 07:59:00  FinancialServices  \n",
       "        2025-01-06 08:00:00  FinancialServices  \n",
       "...                                        ...  \n",
       "MDB     2025-04-04 18:54:00         Technology  \n",
       "        2025-04-04 19:00:00         Technology  \n",
       "        2025-04-04 19:36:00         Technology  \n",
       "        2025-04-04 19:50:00         Technology  \n",
       "        2025-04-04 19:59:00         Technology  \n",
       "\n",
       "[15765758 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = local_candles.load_parquet()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['close'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../models/autogluon-close-minute\"\n",
      "Frequency '1min' stored as 'min'\n",
      "Beginning AutoGluon training... Time limit = 1200s\n",
      "AutoGluon will save models to 'c:\\Users\\Administrator\\finstral-1\\models\\autogluon-close-minute'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.9\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.17763\n",
      "CPU Count:          40\n",
      "GPU Count:          1\n",
      "Memory Avail:       342.34 GB / 383.91 GB (89.2%)\n",
      "Disk Space Avail:   563.19 GB / 1787.27 GB (31.5%)\n",
      "===================================================\n",
      "Setting presets to: fast_training\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': RMSE,\n",
      " 'freq': 'min',\n",
      " 'hyperparameters': {'DeepAR': {'batch_size': 256,\n",
      "                                'epochs': 20,\n",
      "                                'hidden_size': 128,\n",
      "                                'learning_rate': 0.001,\n",
      "                                'num_layers': 4,\n",
      "                                'trainer_kwargs': {'accelerator': 'gpu',\n",
      "                                                   'devices': 1,\n",
      "                                                   'num_workers': 32}},\n",
      "                     'PatchTST': {'batch_size': 256,\n",
      "                                  'epochs': 20,\n",
      "                                  'num_layers': 3,\n",
      "                                  'patch_length': 12,\n",
      "                                  'stride': 6,\n",
      "                                  'trainer_kwargs': {'accelerator': 'gpu',\n",
      "                                                     'devices': 1,\n",
      "                                                     'num_workers': 32}},\n",
      "                     'TemporalFusionTransformer': {'attention_head_size': 4,\n",
      "                                                   'batch_size': 256,\n",
      "                                                   'epochs': 20,\n",
      "                                                   'hidden_size': 128,\n",
      "                                                   'trainer_kwargs': {'accelerator': 'gpu',\n",
      "                                                                      'devices': 1,\n",
      "                                                                      'num_workers': 32}}},\n",
      " 'known_covariates_names': ['industrySector',\n",
      "                            'open',\n",
      "                            'high',\n",
      "                            'low',\n",
      "                            'close',\n",
      "                            'volume',\n",
      "                            'VWAP'],\n",
      " 'num_val_windows': 3,\n",
      " 'prediction_length': 48,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': True,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 1200,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'None' has been resampled to frequency 'min'.\n",
      "Provided train_data has 78754943 rows (NaN fraction=80.0%), 618 time series. Median time series length is 127452 (min=127110, max=127657). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['industrySector']\n",
      "\t\tcontinuous (float): ['open', 'high', 'low', 'close', 'volume', 'VWAP']\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        ['interval', 'end']\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'RMSE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-04-06 01:49:58\n",
      "Models that will be trained: ['TemporalFusionTransformer', 'DeepAR', 'PatchTST']\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 256.4s of the 1025.5s of remaining time.\n",
      "\tWarning: Model has no time left to train, skipping model... (Time Left = 0.0s)\n",
      "\tTime limit exceeded... Skipping TemporalFusionTransformer.\n",
      "Training timeseries model DeepAR. Training for up to 201.6s of the 604.8s of remaining time.\n",
      "\tWarning: Model has no time left to train, skipping model... (Time Left = 0.0s)\n",
      "\tTime limit exceeded... Skipping DeepAR.\n",
      "Training timeseries model PatchTST. Training for up to 60.7s of the 121.4s of remaining time.\n",
      "\tWarning: Model has no time left to train, skipping model... (Time Left = 0.0s)\n",
      "\tTime limit exceeded... Skipping PatchTST.\n",
      "Not fitting ensemble due to lack of time remaining. Time left: -338.4 seconds\n",
      "Training complete. Models trained: []\n",
      "Total runtime: 1374.37 s\n",
      "Trainer has no fit models that can predict.\n",
      "\tWARNING: refit_full functionality for TimeSeriesPredictor is experimental and is not yet supported by all models.\n",
      "Refitting models via `refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix '_FULL' and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `fit` call.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trainer has no fit models that can predict.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 51\u001b[0m\n\u001b[0;32m     12\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepAR\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     }\n\u001b[0;32m     48\u001b[0m }\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Optimized fit configuration\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfast_training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_val_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit_full\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_ensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\n\u001b[0;32m     60\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\autogluon\\timeseries\\predictor.py:769\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, hyperparameter_tune_kwargs, excluded_model_types, num_val_windows, val_step_size, refit_every_n_windows, refit_full, enable_ensemble, skip_model_selection, random_seed, verbosity)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refit_full:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tuning_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping `refit_full` because custom `tuning_data` was provided during `fit`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\autogluon\\timeseries\\predictor.py:1385\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.refit_full\u001b[1;34m(self, model, set_best_to_refit_full)\u001b[0m\n\u001b[0;32m   1375\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mWARNING: refit_full functionality for TimeSeriesPredictor is experimental \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand is not yet supported by all models.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1378\u001b[0m )\n\u001b[0;32m   1380\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRefitting models via `refit_full` using all of the data (combined train and validation)...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mModels trained in this way will have the suffix \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_FULL\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and have NaN validation score.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mThis process is not bound by time_limit, but should take less time than the original `fit` call.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m )\n\u001b[1;32m-> 1385\u001b[0m model_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_best\u001b[49m\n\u001b[0;32m   1386\u001b[0m refit_full_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learner\u001b[38;5;241m.\u001b[39mrefit_full(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_best_to_refit_full:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\autogluon\\timeseries\\predictor.py:1167\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.model_best\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m   1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mmodel_best\n\u001b[1;32m-> 1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\autogluon\\timeseries\\trainer\\abstract_trainer.py:407\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.get_model_best\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names()\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can predict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(models) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m models[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Trainer has no fit models that can predict."
     ]
    }
   ],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=48,\n",
    "    path=\"../models/autogluon-close-minute\",\n",
    "    target=\"target\",\n",
    "    eval_metric=\"RMSE\",\n",
    "    freq=\"1min\",\n",
    "    verbosity=2,\n",
    "    known_covariates_names=['industrySector', 'open', 'high', 'low', 'close', 'volume', 'VWAP']\n",
    ")\n",
    "\n",
    "# Enhanced hyperparameters leveraging your hardware\n",
    "hyperparameters = {\n",
    "    'DeepAR': {\n",
    "        'epochs': 20,\n",
    "        'learning_rate': 1e-3,\n",
    "        'batch_size': 256,\n",
    "        'hidden_size': 128,\n",
    "        'num_layers': 4,\n",
    "        'trainer_kwargs': {\n",
    "            'accelerator': 'gpu',\n",
    "            'devices': 1,\n",
    "            'num_workers': 32\n",
    "        }\n",
    "    },\n",
    "    'PatchTST': {\n",
    "        'epochs': 20,\n",
    "        'batch_size': 256,\n",
    "        'patch_length': 12,\n",
    "        'stride': 6,\n",
    "        'num_layers': 3,\n",
    "        'trainer_kwargs': {\n",
    "            'accelerator': 'gpu',\n",
    "            'devices': 1,\n",
    "            'num_workers': 32\n",
    "        }\n",
    "    },\n",
    "    'TemporalFusionTransformer': {\n",
    "        'epochs': 20,\n",
    "        'batch_size': 256,\n",
    "        'hidden_size': 128,\n",
    "        'attention_head_size': 4,\n",
    "        'trainer_kwargs': {\n",
    "            'accelerator': 'gpu',\n",
    "            'devices': 1,\n",
    "            'num_workers': 32\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Optimized fit configuration\n",
    "predictor.fit(\n",
    "    train_data=df,\n",
    "    presets=\"fast_training\",\n",
    "    time_limit=1200,\n",
    "    hyperparameters=hyperparameters,\n",
    "    num_val_windows=3,\n",
    "    refit_full=True,\n",
    "    enable_ensemble=True,\n",
    "    random_seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(df)\n",
    "predictions.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
